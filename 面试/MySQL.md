# 数据库基础知识





## 元组，码，候选码，主码，主属性，非主属性



- 元组  tuple：是**关系数据库**中的基本概念，关系是一张表，表中的每行（**数据库中的每条记录**）就是一个元组，每列就是一个属性。在二维表里，元组也称为行

- 码：**唯一标识实体的  <属性>，对应表中的列**

- 候选码：关系中的**某一属性或属性组**的值能**唯一的标识一个元组**，而其**任何子集都不能再标识**，则称该属性组为候选码。

  例如：在学生实体中，“学号”是能唯一的区分学生实体的，同时又假设“姓名”、“班级”的属性组合足以区分学生实体，那么{学号}和{姓名，班级}都是候选码。

- **主码** : 主码也叫主键。主码是**从候选码中选出来的**。 一个实体集中只能有一个主码，但可以有多个候选码。

- **外码** : 外码也叫外键。如果一个关系中的一个属性是另外一个关系中的主码则这个属性为外码。

- **主属性** ： **候选码中出现过的属性称为主属性**。比如关系 ：工人（工号，身份证号，姓名，性别，部门）.显然工号和身份证号都能够唯一标示这个关系，所以都是候选码。工号、身份证号这两个属性就是主属性。如果主码是一个属性组，那么属性组中的属性都是主属性。

- **非主属性：** 不包含在任何一个候选码中的属性称为非主属性。比如在关系——学生（学号，姓名，年龄，性别，班级）中，主码是“学号”，那么其他的“姓名”、“年龄”、“性别”、“班级”就都可以称为非主属性。







## 主键和外键有什么区别?



- **主键(主码)** ：主键用于唯一标识一个元组，不能有重复，不允许为空。一个表只能有一个主键。
- **外键(外码)** ：外键用来和其他表建立联系用，外键是另一表的主键，外键是可以有重复的，可以是空值。一个表可以有多个外键。





## 什么是 ER 图？



实体-联系图（Entity Relationship Diagram），提供了表示 **实体类型、属性和联系的方法**，用来描述现实世界的概念模型。它是描述现实世界关系概念模型的有效方法。

学生选课的 ER 图，每个学生可以选若干门课程，同一门课程也可以被若干人选择，**多对多关系（M:N）**



![image-20210611235640531](../picture/MySQL/image-20210611235640531.png)



将ER图转为数据库实际的关系模型：

![image-20210612000728350](../picture/MySQL/image-20210612000728350.png)





## 数据库三范式





**1NF(第一范式)**

属性（对应于表中的字段）不能再被分割，也就是这个字段只能是一个值，不能再分为多个其他的字段了。**1NF是所有关系型数据库的最基本要求** ，也就是说关系型数据库中创建的表一定满足第一范式。

**2NF(第二范式)**

2NF在1NF的基础之上，消除了非主属性对于码的**部分函数依赖**。如下图所示，展示了第一范式到第二范式的过渡。第二范式在第一范式的基础上增加了一个列，这个列称为主键，非主属性都依赖于主键。

> 增加一个主键，进行属性的拆分，如果不是一一对应的属性（没有直接依赖），就拆出单独一个表

![image-20210612002813741](../picture/MySQL/image-20210612002813741.png)



![image-20210612140828919](../picture/MySQL/image-20210612140828919.png)







---

一些重要的概念：

- **函数依赖（functional dependency）** ：若在一张表中，在属性（或属性组）X的值确定的情况下，必定能确定属性Y的值，那么就可以说Y函数依赖于X，写作 X → Y。

- **部分函数依赖（partial functional dependency）** ：如果X→Y，并且存在X的一个真子集X0，使得X0→Y，则称**Y对X部分函数依赖**。比如学生基本信息表R中（学号，身份证号，姓名）当然学号属性取值是唯一的，在R关系中，（学号，身份证号）->（姓名），（学号）->（姓名），（身份证号）->（姓名）；所以姓名部分函数依赖与（学号，身份证号）；

- **完全函数依赖(Full functional dependency)** ：在一个关系中，若某 个**非主属性**数据项**依赖于全部关键字**称之为完全函数依赖。比如学生基本信息表R（学号，班级，姓名）假设不同的班级学号有相同的，班级内学号不能相同，在R关系中，（学号，班级）->（姓名），但是（学号）->(姓名)不成立，（班级）->(姓名)不成立，所以姓名完全函数依赖与（学号，班级）；

- **传递函数依赖** ： 在关系模式R(U)中，设X，Y，Z是U的不同的属性子集，如果X确定Y、Y确定Z，且有X不包含Y，Y不确定X，（X∪Y）∩Z=空集合，则称Z传递函数依赖(transitive functional dependency) 于X。传递函数依赖会导致数据冗余和异常。传递函数依赖的Y和Z子集往往同属于某一个事物，因此可将其合并放到一个表中。

  比如在关系R(学号 ,姓名, 系名，系主任)中，学号 → 系名，系名 → 系主任，所以存在**非主属性**系主任对于学号的传递函数依赖。

---

**3NF(第三范式)**

3NF在2NF的基础之上，消除了非主属性对于码的传递函数依赖 。符合3NF要求的数据库设计，**基本**上解决了数据冗余过大，插入异常，修改异常，删除异常的问题。比如在关系R(学号 ,姓名, 系名，系主任)中，学号 → 系名，系名 → 系主任，所以存在非主属性系主任对于学号的传递函数依赖，所以该表的设计，不符合3NF的要求。

![image-20210612140806747](../picture/MySQL/image-20210612140806747.png)









**总结**

- 1NF：属性不可再分。（**每个属性只能表示一个含义**）
- 2NF：1NF的基础之上，消除了非主属性对于码的部分函数依赖。
- 3NF：3NF在2NF的基础之上，消除了非主属性对于码的**传递函数依赖** 。





## 存储过程



一些 SQL 语句的集合，中间加了逻辑控制语句。

在 **业务复杂** 的时候很实用，比如很多时候我们完成一个操作可能需要写一大串SQL语句，这时候我们就可以写有一个存储过程，这样也方便了我们下一次的调用。

另外，使用存储过程**比单纯SQL语句执行要快**，因为存储过程是**预编译过的。**

存储过程在互联网公司应用不多，因为存储过程难以调试和扩展，而且没有移植性，还会消耗数据库资源。

阿里巴巴Java开发手册里要求禁止使用存储过程！



![阿里巴巴Java开发手册:禁止存储过程](../picture/MySQL/image-20210612115423591.png)





## drop、delete与truncate区别？



- drop（**丢弃数据**）：`drop table 表名`，直接将整个表删除，在删除表的时候使用
- truncate (清空数据) : `truncate table 表名` ，只删除表中的数据，再插入数据的时候自增长id又从1开始，在清空表中数据的时候使用。
- delete（删除数据） : `delete from 表名 where 列名=值`，删除某一列的数据，如果不加 where 子句和`truncate table 表名`作用类似。（自增id不会变小）



truncate 和不带 where 子句的 delete、以及 drop 都会删除表内的数据，但是 **truncate 和 delete 只删除数据不删除表的结构(定义)，执行drop语句，此表的结构也会删除，也就是执行 drop 之后对应的表不复存在。**



---

***它们属于不同的数据库语言！***

truncate和drop 属于DDL(数据定义语言)语句，**操作立即生效，原数据不放到 rollback segment 中，<不能回滚>**，操作不触发 trigger。

而 delete 语句是**DML (数据库操作语言)**语句，这个操作会放到 **rollback segement 中，<u>事务提交之后才生效</u>。**



---

**DML 语句和 DDL 语句区别：**

- DML 是**数据库操作语言（Data Manipulation Language）**的缩写，是指对数据库中**<表记录的操作>**，主要包括**表记录的插入（insert）、更新（update）、删除（delete）和查询（select）**，是开发人员日常使用最频繁的操作。
- DDL 是**数据定义语言（Data Definition Language）**的缩写，简单来说，就是对数据库内部的对象进行创建、删除、修改的操作语言。它和 DML 语言的最大区别是 DML 只是对表内部数据的操作，而不涉及到表的定义、结构的修改，更不会涉及到其他对象。DDL 语句更多的被数据库管理员（DBA）所使用，一般的开发人员很少使用。



---

**执行速度不同？**

一般来说:drop>truncate>delete（这个我没有设计测试过）。











# 什么是 MySQL



**关系型数据库**，因为MySQL是开源免费的，方便扩展。阿里巴巴数据库系统也大量用到了mysql，稳定性有保障！

mysql开放源代码，可以对其进行个性化的修改。

默认端口号是 3306





# 事务







## 什么是事务



**事务就是逻辑上的一组操作，要么都执行，要么都不执行**

> 假如小明要给小红转账1000元，这个转账会涉及到两个关键操作就是：将小明的余额减少1000元，将小红的余额增加1000元。万一在这两个操作之间突然出现错误比如银行系统崩溃，导致小明余额减少而小红的余额没有增加，这样就不对了。事务就是保证这两个关键操作要么都成功，要么都要失败。





## 事物的四大特性(ACID)





1. **原子性**：事务是最小的执行单位，**不允许分割**。**确保事务这个动作要么全部完成，要么完全不起作用**
2. **一致性**：执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的。如：转账前2个人的 总金额 是 2000，转账后 2 个人总金额也是 2000.
3. **隔离性**： **事务与事务之间不应该相互影响，执行时保持隔离的状态.**         事务是并发控制机制，他们交错使用时也能提供一致性。隔离让我们隐藏来自外部世界未提交的状态变化，一个失败的事务不应该破坏系统的状态。隔离是通过用**悲观或乐观锁机制实现的。**
4. **持久性**：一旦事务执行成功，对数据库的**修改是持久的**。就算关机，数据也是要保存下来的





## 并发事务带来哪些问题





一个数据库可能拥有**多个访问客户端**,这些客户端都可以**并发方式访问数据库**. 数据库的相同数据可能被**多个事务同时访问**,如果**不采取隔离措施,就会导致各种问题, 破坏数据的完整性**  



- **脏读（Dirty read）**：一个事务正在访问数据并且**对数据进行了修改**，而这种修改**还没有提交**到数据库中，**这时另外一个事务也访问了这个数据，然后使用了这个数据**。因为这个数据是**还没有提交的数据**，那么另一个事务读到的这个数据是**“脏数据”**，依据"脏数据"所做的操作可能是不正确的。

- **丢失修改（Lost to modify）**：指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样**第一个事务内的修改结果就被丢失**，因此称为**丢失修改**。 

  例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，**事务1的修改被丢失。**

- **不可重复读（Unrepeatableread）**：指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于**第二个事务的修改导致第一个事务两次读取的数据可能不太一样**。这就发生了**在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。**

- **幻读（Phantom read）**：幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）**<插入>**了一些数据时。在随后的查询中，第一个事务（T1）就会发现**多了一些原本不存在的记录**，就好像**发生了幻觉一样**，所以称为幻读。



## 不可重复读和幻读区别



- **不可重复读的重点是  修改**

- **幻读的重点在于 新增或删除**



> 例1（同样的条件, 你读取过的数据, 再次读取出来发现值不一样了 ）：事务1中的A先生读取自己的工资为 1000的操作还没完成，事务2中的B先生就修改了A的工资为2000，导 致A再读自己的工资时工资变为 2000；这就是不可重复读。



> 例2（同样的条件, 第1次和第2次读出来的记录数不一样 ）：假某工资单表中工资大于3000的有4人，事务1读取了所有工资大于3000的人，共查到4条记录，这时事务2 又插入了一条工资大于3000的记录，事务1再次读取时查到的记录就变为了5条，这样就导致了幻读。





## 事务的隔离级别有哪些？MySQL的默认隔离级别是？





SQL 标准定义了四个隔离级别：

- **READ-UNCOMMITTED(读取未提交)：** 最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**。
- **READ-COMMITTED(读取已提交)：** 允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**。
- **REPEATABLE-READ(可重复读)：** 对同一字段的多次读取结果都是一致的，除非数据是被本身**事务自己所修改**，**可以阻止脏读和不可重复读，但<幻读仍有可能发生>**。
- **SERIALIZABLE(可串行化)：** 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。



|     隔离级别     | 脏读 | 不可重复读 | 幻影读 |
| :--------------: | :--: | :--------: | :----: |
| READ-UNCOMMITTED |  √   |     √      |   √    |
|  READ-COMMITTED  |  ×   |     √      |   √    |
| REPEATABLE-READ  |  ×   |     ×      |   √    |
|   SERIALIZABLE   |  ×   |     ×      |   ×    |



MySQL InnoDB 存储引擎**默认**支持的隔离级别是 **REPEATABLE-READ 可重复读**，通过命令 `SELECT @@tx_isolation;`  mysql8 ：`SELECT @@transaction_isolation;`

![image-20210612173754815](../picture/MySQL/image-20210612173754815.png)



与 SQL 标准不同的地方：**<u>InnoDB存储引擎</u>**  在  **REPEATABLE-READ（可重读）**事务隔离级别下使用的是 **Next-Key Lock 锁算法**， 因此可以避免幻读的产生，这与其他数据库系统 （SQL Server）是不同的。

所以说InnoDB 存储引擎的默认支持的隔离级别是 **REPEATABLE-READ（可重读）** 已经**可以完全保证事务的隔离性要求**，即达到了 SQL标准的**SERIALIZABLE(可串行化)**隔离级别。



> InnoDB 存储引擎在 **分布式事务** 的情况下一般会用到**SERIALIZABLE(可串行化)**隔离级别



----

在实现上，数据库里面会**创建一个视图**，访问的时候**以视图的逻辑结果为准**。

- 在“可重复读”隔离级别下，这个视图是在**事务启动时创建**的，整个事务存在期间都用这个视图，**所以读到的某个数据其实都是一个值，不会被其他事务改变**
- “读提交”隔离级别下，这个视图是在**每个 SQL 语句开始执行**的时候创建的。这样就可以读到其他最新提交事务的数据，但会出现"不可重复读"问题
- “读未提交”隔离级别下直接**返回记录上的最新值**，**没有视图概念**
- “串行化”隔离级别下直接用**加锁**的方式来避免并行访问。



不同的隔离级别下， 数据库行为是有所不同的。 **Oracle数据库的默认隔离级别其实就是“读提交”**， 因此对于一些从Oracle迁移到MySQL的应用， 为保证数据库隔离级别的一致，你一定要记得将MySQL的隔离级别设置为“读提交”  

不同的隔离级别下， 数据库行为是有所不同的。 Oracle数据库的默认隔离级别其实就是“读提交”， 因此对于一些从Oracle迁移到MySQL的应用， 为保证数据库隔离级别的一致，你一定要记得将MySQL的隔离级别设置为“读提交”  



可以将启动参数`transaction-isolation`的值设置成`四种隔离级别`。 

```sql
set global transaction isolation level  read uncommitted / read committed / repeatable read / SERIALIZABLE;
```

你可以用`show variables`来查看当前的值  

```sql
show variables like 'transaction_isolation';
```

![image-20210616184006409](../picture/MySQL/image-20210616184006409.png)



----

"存在即合理"，每个隔离级别都有它自己的使用场景，根据业务来定。

**什么时候需要“可重复读”的场景呢？**这有一个数据校对的:chestnut:

假设你在管理一个个人银行账户表。 一个表存了每个月月底的余额， 一个表存了账单明细。 这时候你要做数据校对， 也就是判断上个月的余额和当前余额的差额， 是否与本月的账单明细一致。

你一定希望**在校对过程中， 即使有用户发生了一笔新的交易， 也不影响你的校对结果。**

这时候使用“可重复读”隔离级别就很方便。 事务启动时的视图可以认为是静态的， **不受其他事务更新的影响**。  



## 事务隔离的实现



这里重点说明“可重复读”

每条记录在更新的时候都会同时***记录一条回滚操作***。记录上的最新值，通过回滚操作，都可以得到**前一个状态的值**。

假设一个值从1被按顺序改成了2、 3、 4， 在回滚日志里面就会有类似下面的记录  

![image-20210616184820864](../picture/MySQL/image-20210616184820864.png)



当前值最终被修改为了4，但是在查询这条记录的时候，**不同时刻启动的事务**会有不同的 **read-view**。

A、B、C相当于一个记录在三个事务a、b、c启动时的状态，此时事务a想获得这个自己事务中的这个值，那么就需要回滚到 read-view A。

在视图 A、B、C 里面，这一个记录的值分别为1 、2 、4，**同一条记录**在系统中可以**存在多个版本**，就是数据库的 **多版本并发控制 MVCC**。

对于 read-view A，要得到 1，就必须将当前值**依次执行图中所有回滚操作得到**。

同时会发现，即使现在还有一个事务正在将4改成5，这个事务跟 read-view A、B、C对应的事务是**不会冲突的**。

回滚日志在不需要的时候删除！系统会判断，当没有事务再需要用到这些回滚日志的时候，回滚日志会被删除。什么时候才不需要呢？？**当系统里没有比这个回滚日志更早的 read-view 的时候。**



---

**尽量不要使用长事务！**

长事务意味着系统里面会**存在很老的事务视图**。由于这些事务随时可能访问数据库里的任何数据，所以**这个事务提交之前**，数据库里面它可能用到的所有的回滚记录都必须保留，导致**大量占用存储空间**

在MySQL 5.5及以前的版本， **回滚日志是跟数据字典一起放在ibdata文件里的**， 即使长事务最终提交， 回滚段被清理， 文件也不会变小。 我见过数据只有20GB， 而回滚段有200GB的库。 最终只好为了清理回滚段， 重建整个库。

除了对回滚段的影响， 长事务还占用锁资源  





---

## 事务的启动方式



长事务有潜在风险，尽量避免。其实很多时候是由于误用导致。

MySQL的事务启动方式有以下几种：

1. 显示启动事务语句，`begin 或 start transaction`。配套的提交语句是 `commit`，回滚语句是 `rollback`
2. `set autocommit=0`，这个命令会将这个线程的 **自动提交关掉**。意味着如果你只执行一个**select**语句， **这个事务就启动了**， 而且并**不会自动提交**。 这个事务持续存在**直到你主动执行commit 或 rollback 语句**， 或者断开连接。  

![image-20210616194435021](../picture/MySQL/image-20210616194435021.png)



有些客户端连接框架会默认连接成功后先执行一个set autocommit=0的命令。 这就导致**接下来的查询都在事务中**， 如果是长连接， 就导致了意外的长事务。

**因此， 建议总是使用set autocommit=1, 通过显式语句的方式来启动事务，如果没有通过显式语句启动事务，那么都是自动提交的事务**  



对于一个需要频繁使用事务的业务， 第二种方式每个事务在开始时都不需要主动执行一次 “begin”， 减少了语句的交互次数。 如果你也有这个顾虑， 我建议你使用`commit work and chain`语法。

在autocommit为1的情况下， 用begin显式启动的事务， 如果执行commit则提交事务。 如果**执行commit work and chain**， 则是**提交事务并自动启动下一个事务**， 这样也省去了再次执行begin语句的开销。 同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。



> **可以在`information_schema`库的`innodb_trx`这个表中查询长事务， 比如下面这个语句， 用于查找持续时间超过60s的事务。**  
>
> ```mysql
> select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started)) > 60
> ```



---

## 如何避免长事务对业务的影响



系统里面应该避免长事务， 如果你是业务开发负责人同时也是数据库负责人， 你会有什么方案来避免出现或者处理这种情况呢？  



从应用开发端和数据库端来看。

**应用开发端：**

1. 确认是否使用了 `set autocommit=0`。这个确认工作可以在测试环境中开展， 把MySQL的`general_log`开起来， 然后随便跑一个业务逻辑， 通过general_log的日志来确认。 一般框架如果会设置这个值， 也就会提供参数来控制行为， 你的目标就是把它改成1。  

2. 确认是否有不必要的只读事务。 有些框架会习惯不管什么语句先用begin/commit框起来。 我见过有些是业务并没有这个需要， 但是也把好几个select语句放到了事务中。 **这种只读事务可以去掉，只读事务不需要进事务！**

3. 业务连接数据库的时候， 根据业务本身的预估， 通过`SETMAX_EXECUTION_TIME`命令，来**控制每个语句执行的最长时间**， 避免单个语句**意外（见后面笔记~）**执行太长时间。 



**从数据库端来看：**

1. 监控 `information_schema.Innodb_trx  `表，设置**长事务阈值**，超过就报警 /  kill

2. Percona的pt-kill这个工具不错， 推荐使用；  

3. 在业务功能测试阶段要求输出所有的general_log， 分析日志行为提前发现问题；  

4. 如果使用的是MySQL 5.6或者更新版本， 把`innodb_undo_tablespaces`设置成2（或更大的值） 。 如果真的出现**大事务导致回滚段过大**， 这样设置后清理起来更方便。  

> 有关undo log：
>
> https://blog.csdn.net/w892824196/article/details/100163555















# 索引



> **索引的出现就是为了提高数据查询的效率，就像书的目录一样**



![[思维导图-索引篇]](../picture/MySQL/f3f34283a61ddb8d86bad05062e1f824.jpg)











## 为什么索引能提高查询的速度





---

### **MySQL 的基本存储结构**



MySQL的基本存储结构是页（记录都存在页里边）：（InnoDB）

![MySQL的基本存储结构是页](../picture/MySQL/53fb4b0ab69f265fc87d2644b6ec16e9.jpg)







![img](../picture/MySQL/6221ec727fc769fcd43c1cb8e84eac8c.jpg)



- **各个数据页可以组成一个<<u>双向链表</u>>**

- **每个数据页中的记录又可以组成一个<u>单向链表</u>**
  - **每个数据页**都会为存储在它里面的记录生成一个页目录，在**通过主键查找**某条记录的时候会在页目录中使用**二分法快速定位到对应的槽**，然后再**遍历**该槽对应分组中的记录即可快速找到指定的记录
  - 以其他列（非主键）作为搜索条件：只能从最小记录开始**依次遍历单链表中的每条记录**



所以：如果我们写  `select * from user where indexname = 'xxx'` 这样没有进行 **任何优化** 的sql语句，默认会这样做：

1. **定位到记录所在的页：需要遍历双向链表，找到所在的页**
2. **从所在的页内查找相应的记录：由于不是根据主键查询，只能遍历所在页的单链表**

时间复杂度：O(n)



**索引做了些什么可以让我们查询加快速度呢？将无序的数据变成相对有序**

![img](../picture/MySQL/bcc5199d6a4e4f29351af6e2189410a3.jpg)



> **分多个层级，最顶层的页存放下一层的页号（非叶子的页中有字段记录当前页存放的记录id的范围，这样才能确定该走哪个子树），下一层的页号存放普通目录项记录，再下一层是根据id对记录排好序**



要找到id为8的记录简要步骤：

![img](../picture/MySQL/d101732ebc32f1e92480fe4b90ce933d.jpg)



没有使用索引，就需要遍历双向链表来定位对应的页，现在通过目录就能很快定位到对应的页！（二分查找，时间复杂度近似为O(logn)）

然后在页内遍历单向链表找到对应的记录！

**底层结构就是 B+ 树，B+树作为树的一种实现，能够让我们很快地查找出对应的记录**





## 索引的优缺点

优点

- 使用索引可以大大加快 **数据的检索速度**（**<u>大大减少检索的数据量</u>**），这也是创建索引的最主要的原因
- 通过创建 **<u>唯一性索引</u>**，可以保证数据库表中每一行**数据的唯一性**



缺点：

- 创建索引和维护索引需要耗费许多时间。当对表中的数据进行增删改的时候，如果数据有索引，那么**索引也需要动态的修改，会降低 SQL 执行效率。**
- 索引需要**使用物理文件存储，也会耗费一定空间**。



但是，**使用索引一定能提高查询性能吗?**

大多数情况下，索引查询都是比全表扫描要快的。但是如果数据库的数据量不大，那么使用索引也不一定能够带来很大提升。





## 索引的常见模型



### Hash表 

哈希表是键值对的集合，可以做到快速检索数据（近乎O(1)复杂度）

比如现在维护一个身份证信息和姓名的表，需要根据身份证号查找对应的名字：

![image-20210616222808700](../picture/MySQL/image-20210616222808700.png)

假设，这时候要查ID_card_n2对应的名字是什么， 处理步骤就是： 首先， 将ID_card_n2通过哈希函数算出N； 然后， 按顺序遍历， 找到User2  

**这种结构增加新的 User 时速度会很快，只需要往后追加。但是因为不是有序的，做区间查询的速度很慢！**

比如：现在要找身份证号在`[ID_card_X, ID_card_Y]`这个区间的所有用户， 就必须**全部扫描一遍了**  



综上，**哈希表这种结构适用于只有等值查询的场景，比如Memcached及其他一些NoSQL引擎**



> 就不介绍哈希算法了。。。
>
> 哈希算法出现**Hash冲突**，不同的 key 最后得到的 index 相同。**链地址法 -> 红黑树**

**既然哈希表这么快，为什么 MySQL 没有使用其作为索引的数据结构呢？**

1. **Hash 冲突问题**
2. **Hash 索引不支持<顺序和范围查询>  ——>  这是它最大的缺点**：假如我们要对表中的数据进行排序或者进行范围查询，那 Hash 索引就不行了

:chestnut:

```java
SELECT * FROM tb1 WHERE id < 500;Copy to clipboardErrorCopiedCopy to clipboardErrorCopied
```

**B+树** 在这种**范围查询**中，优势非常大，**直接遍历比 500 小的叶子节点就够了**。

而 Hash 索引是**根据 hash 算法来定位**的，难不成还要把 1 - 499 的数据，**<u>每个都进行一次 hash 计算来定位</u>**吗?这就是 Hash 最大的缺点了。







### 有序数组



**有序数组在等值查询和范围查询场景中的性能都非常优秀**

还是上面的:chestnut:，如果使用有序数组来实现的话：

![image-20210616223226926](../picture/MySQL/image-20210616223226926.png)

这个数组按照身份证号递增的顺序保存的，如果需要查ID_card_n2对应的名字， 用**二分法**就可以快速得到， 这个时间复杂度是**O(log(N))**。  



同时很显然， 这个索引结构**支持范围查询**。 你要查身份证号在[ID_card_X, ID_card_Y]区间的User， 可以先用二分法找到ID_card_X（如果不存在ID_card_X， 就找到大于ID_card_X的第一个User） ， 然后向右遍历， 直到查到第一个大于ID_card_Y的身份证号， 退出循环。  



如果仅仅看查询效率， 有序数组就是最好的数据结构了。 但是， 在需要**更新数据**的时候就麻烦了， 你往中间**插入一个记录就必须得挪动后面所有的记录， 成本太高。**  

**所以，有序数组索引只适用于静态存储引擎**，比如：要保存的是2017年某个城市的所有人口信息， 这类**不会再修改的数据**。  











### 二叉搜索树







还是上面的:chestnut:

![二叉搜索树示意图](../picture/MySQL/image-20210616223448495.png)

每个节点的左儿子小于父节点，父节点小于右儿子

如果要查ID_card_n2的话， 按照图中的搜索顺序就是按照UserA -> UserC -> UserF -> User2这个路径得到。 这个时间复杂度是**O(log(N))**  

多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。虽然二叉树是**搜索效率最高**的， 但是实际上**大多数的数据库存储却并不使用二叉树**。 

其原因是， **索引不止存在内存中， 还要写到磁盘上。**  

> 你可以想象一下一棵**100万节点**的平衡二叉树， **树高20**。 一次查询可能需要**访问20个数据块**。 在机械硬盘时代， 从磁盘随机读一个数据块需要10 ms左右的寻址时间。 也就是说， 对于一个100万行的表， 如果使用二叉树来存储， 单独访问一个行可能需要20个10 ms的时间， 这个查询可真够慢的。  
>
> **慢的主要原因还是树太高了！那么就使用多叉树来降低树的高度！并且减少数据块的访问次数**



为了让一个查询尽量少地读磁盘， 就必须让查询过程访问尽量少的数据块。 那么， 我们就不应该使用二叉树， 而是要使用“N叉”树。 这里， **“N叉”树中的“N”取决于数据块的大小。**  



以 InnoDB 的一个整数字段索引为例，**这个 N 差不多是 1200**。这棵树的高度为4的时候(树根的数据库总是在内存中)，就可以存  `1200的3次方个值 ≈ 17亿`。一个 十亿行 的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。（树的第二层也有很大概率在内存中，访问次数更少！）



N叉树 **在读写上的性能优点，以及适配磁盘的访问模式，被广泛用于数据库引擎中！**



哈希表 -> 有序数组 -> 二叉树 -> N叉树 ，都是在不断迭代！不断优化！直到今天，跳表、LSM树等数据结构也被用于引擎设计中。



> **数据库底层存储的核心就是基于这些数据模型的**。 每碰到一个新数据库， 我们需要**先关注它的数据模型**， 这样才能**从理论上分析出这个数据库的适用场景。**  













### B树 & B+树



在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式称为**索引组织表**。



假设， 我们有一个主键列为ID的表， 表中有字段k， 并且在k上有索引。  

```mysql
create table T(
	id int primary key,
	k int not null,
	name varchar(16),
	index (k) ## 为字段 k 也建一个索引
)engine=InnoDB;
```

表中R1~R5的(ID,k)值分别为(100,1)、 (200,2)、 (300,3)、 (500,5)和(600,6)， 两棵树的示例示意图如下  

![InnoDB的索引组织结构](../picture/MySQL/image-20210616230802155.png)

根据叶子节点的内容，索引类型分为主键索引和非主键索引。

- 主键索引的叶子节点存的是整行数据。 在InnoDB里， 主键索引也被称为聚簇索引（clustered index）  

- 非主键索引的叶子节点内容是主键的值。 在InnoDB里， 非主键索引也被称为二级索引（secondaryindex）   

> 基于非主键索引的查询需要多扫描一棵索引树。 因此， 我们在应用中应该尽量使用主键查询。





B树 也称为 B-树，全称：**多路平衡查找树**。B+树 是 B 树的一种变体。

> B：Balanced **平衡**

**大部分数据库系统以及文件系统都采用 B- 树 或其变种 B+ 树作为索引结构**





---

**B树和B+树两者的异同？**



- B 树的所有节点 **既存放 key，也存放 data**，而B+树 **只有<叶子结点>存放key 和 data，其他内节点只存放 key**

- B 树的 叶子节点都是 **独立**的；**B+树的叶子节点有一条 <引用链> 指向与它相邻的叶子节点**

- B 树的检索过程相当于对 范围内的**每个节点的关键字做二分查找**，可能还没到达叶子节点，检索就结束了。

  而B+树 **检索效率很稳定：任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显**



![img](../picture/MySQL/20210420165409106.png)

> 只有叶子节点存储数据（**即表的具体记录，非叶子节点不保存具体记录，保存的是数据页的目录表**）



在 MySQL 中，MyISAM 引擎和 InnoDB 引擎都是使用的 B+Tree 作为索引结构，**但两者的实现方式不太一样**：

- MyISAM 引擎中，**B+Tree 叶节点的 data 域存放的是数据记录的地址**。在索引检索的时候，首先按照 B+Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后**以 data 域的值为地址读取相应的数据记录**。

  这被称为**“非聚簇索引”**。

- InnoDB 引擎中，其**数据文件本身就是索引文件**。相比 MyISAM，索引文件和数据文件是分离的，其**表数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录**。

  这个索引的 **key 是数据表的主键**，因此 InnoDB 表数据文件本身就是主索引。这被称为“**聚簇索引**（或聚集索引）”，而其余的索引都作为**辅助索引**，辅助索引的 ***data 域存储相应记录<主键的值>而不是地址***，这也是和 MyISAM 不同的地方。

  在根据主索引搜索时，直接找到 key 所在的节点即可取出数据；

  在根据辅助索引查找时，则需要**先取出主键的值，在走一遍主索引**。 

  因此，在设计表的时候，**不建议使用过长的字段作为主键**，也**不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。**





## 索引维护



B+ 树 为了维护索引的有序性，在插入新值的时候需要做必要的维护。

以这个图为例：

![image-20210616231921472](../picture/MySQL/image-20210616231921472.png)

如果插入新的行ID值为 700，则只需要在 R5 的记录后面插入一个新纪录，如果插入的ID值为 400，就相对麻烦了，需要**<u>逻辑上挪动</u>**后面的数据，空出位置

更糟的是，如果 R5 所在的数据页满了，根据B+树的算法，需要申请一个新的数据页，然后挪动部分数据过去。**页分裂**。这种情况下，性能自然会受到影响！

除了性能外， 页分裂操作还影响**数据页的利用率**。 原本放在一个页的数据， 现在分到两个页中，**整体空间利用率降低大约50%。**  



当然**有分裂就有合并**。 当相邻两个页**由于删除了数据， 利用率很低之后， 会将数据页做合并**。 合并的过程， 可以认为是分裂过程的逆过程  



来一个:chestnut:

> 可能在一些建表规范里面见到过类似的描述， 要求**建表语句里一定要有自增主键**。 当然事无绝对， 我们来分析一下**哪些场景下应该使用自增主键， 而哪些场景下不应该。**  

自增主键是指自增列上定义的主键，在建表语句中一般是这么定义的：

```
Not Null Primary Key auto_increment
```

插入新记录的时候可以不指定ID的值， 系统会获取当前ID最大值加1作为下一条记录的ID值。  

也就是说， 自增主键的插入数据模式， 正符合了我们前面提到的**<u>递增插入</u>**的场景。 每次插入一条新记录， **都是追加操作**， 都**不涉及到挪动其他记录， 也不会触发叶子节点的分裂**。  



如果使用有**业务逻辑**的字段做主键，则往往**不容易保证有序插入**，写数据成本高

假如**表中确实有一个唯一字段**，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？

由于每个非主键索引（二级索引）的叶子节点上都是主键的值。 如果用身份证号做主键， 那么每个**二级索引的叶子节点占用约20个字节**， 而如果用整型做主键， 则只要4个字节， 如果是长整型（bigint） 则是 8 个字节

**显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小**



所以，从 **性能和存储空间** 方面考量，自增主键往往是更合理的选择。

有些业务场景的需求：

1. 只有一个索引
2. 该索引必须是唯一索引

这就是典型的**KV场景**。

由于没有其他索引， 所以也就***不用考虑其他索引的叶子节点大小的问题***。

这时候我们就要优先考虑上一段提到的“尽量使用主键查询”原则， 直接将这个索引设置为主键，可以**避免每次查询需要搜索两棵树**。  





## 重建索引





如果要重建索引 k，两个 SQL 语句可以这么写

```mysql
alter table T drop index k;
alter table T add index(k);
```

如果要重建主键索引：

```mysql
alter table T drop primary key;
alter table T add primary key(id);
```



:question: 对于上面这两个重建索引的作法， 说出你的理解。 

**如果有不合适的， 为什么， 更好的方法是什么？**  



---

通过两个 alter 语句重建索引 k，以及通过两个 alter 语句重建主键索引是否合理

:question: 为什么要重建索引？

索引可能因为删除，或者叶分裂等原因，**导致数据页有空洞**，重建索引会创建一个新的索引，把数据按顺序插入，这样页的利用率最高，**使得索引更紧凑、更省空间**



重建索引 k 的做法是 **合理的**:+1: ，可以达到省空间的目的。

但是重建主键的过程不合理。不论是删除主键还是创建主键，都**会将整个表重建**。**这样的话，重建索引 k 的语句就白做了！**

这两个语句，可以用一个语句代替：

```mysql
alter table T engine=InnoDB
```

详见：《为什么表数据删掉一半， 表文件大小不变？ 》   































## 索引类型





### 主键索引 Primary Key



数据库表的主键使用的就是主键索引

**一张数据表有只能有一个主键，并且主键不能为 null，不能重复。**

在 MySQL 的 InnoDB 的表中，当没有显示的指定表的主键时，InnoDB 会自动先检查表中是否有唯一索引的字段，如果有，则选择该字段为默认的主键，否则 InnoDB 将会自动创建一个 **6Byte 的自增主键（不会显示在表中，存储结构中用到）**



### 二级索引 (辅助索引)



**二级索引又称为辅助索引，是因为二级索引的叶子节点存储的数据是主键。也就是说，通过二级索引，可以定位主键的位置。**

唯一索引，普通索引，前缀索引等索引属于二级索引。

**PS:不懂的同学可以暂存疑，慢慢往下看，后面会有答案的，也可以自行搜索。**

1. **唯一索引(Unique Key)** ：唯一索引也是一种约束。**唯一索引的属性列不能出现重复的数据，但是<u>允许数据为 NULL</u>，一张表允许创建多个唯一索引。** 建立唯一索引的目的大部分时候都是为了该属性列的数据的唯一性，而**不是为了查询效率**。
2. **普通索引(Index)** ：**普通索引的<u>唯一作用就是为了快速查询数据</u>，一张表允许创建多个普通索引，并<u>允许数据重复和 NULL</u>。**
3. **前缀索引(Prefix)** ：前缀索引只适用于**字符串类型**的数据。前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小， 因为只取前几个字符。
4. **全文索引(Full Text)** ：全文索引主要是为了**检索大文本数据中的关键字**的信息，是目前搜索引擎数据库使用的一种技术。Mysql5.6 之前只有 MYISAM 引擎支持全文索引，5.6 之后 InnoDB 也支持了全文索引。

**二级索引（辅助索引）：叶子节点的key值为该索引的排序字段，data值为该记录对应的主键id，需要再去主键索引中查询**

![img](../picture/MySQL/20210420165254215.png)







## 聚集索引和非聚集索引





### 聚集索引 



**聚集索引即索引结构和数据一起存放的索引。主键索引属于聚集索引。**

在 Mysql 中，InnoDB 引擎的表的 **`.ibd`文件就包含了该表的索引和数据**，对于 InnoDB 引擎表来说，该表的索引(B+树)的**每个非叶子节点存储索引**，**叶子节点存储索引和索引对应的数据**。



---

**聚集索引的优点**

聚集索引的查询速度非常的快，因为整个 B+树本身就是一颗多叉平衡树，叶子节点也都是有序的，定位到索引的节点，就相当于定位到了数据。



---

**聚集索引的缺点**

1. **依赖有序的数据**：B+树是多路平衡树，如果索引的数据不是有序的，那么就**需要在插入时排序**，如果数据是整型还好排序，否则类似于字符串或 UUID 这种又长又难比较的数据，**插入或查找的速度肯定比较慢**
2. **更新代价大**： 如果对索引列的数据被修改时，那么对应的索引也将会被修改， 而且况聚集索引的叶子节点还存放着数据，修改代价肯定是较大的， 所以**对于主键索引来说，主键一般都是不可被修改的。（所以基本都设置为自增主键）**











### 非聚集索引



**非聚集索引即索引结构和数据分开存放的索引。**

**<u>InnoDB中的二级索引</u> 或 <u>MyISAM的索引结构</u>   是非聚集索引。**



> MYISAM 引擎的表的**.MYI 文件包含了表的索引**， 该表的索引(B+树)的每个叶子非叶子节点存储索引， 叶子节点存储索引和索引对应数据的指针，指向**.MYD 文件的数据**。
>
> **非聚集索引的叶子节点并不一定存放数据的指针， 因为二级索引的叶子节点就存放的是主键，根据主键再回表查数据。**



----

**非聚集索引的优点**

**更新代价比聚集索引要小** 。非聚集索引的更新代价就没有聚集索引那么大了，非聚集索引的叶子节点是不存放数据的



---

**非聚集索引的缺点**

1. 非聚集索引也依赖于 **有序的数据**

2. **可能会二次查询（回表）**：这应该是非聚集索引最大的缺点了。 当查到索引对应的指针或主键后，可能还需要**根据指针或主键再到数据文件或表中查询。**



![img](../picture/MySQL/20210420165311654.png)



![img](../picture/MySQL/20210420165326946.png)



### 非聚集索引一定需要回表查询吗（覆盖索引）



**非聚集索引不一定回表查询。**

> 试想一种情况，用户准备使用 SQL 查询用户名，而用户名字段正好建立了索引。

```text
 SELECT name FROM table WHERE name='guang19';
```

> 那么这个索引的 key 本身就是 name，查到对应的 name 直接返回就行了，无需回表查询。

**即使是 MYISAM 也是这样，虽然 MYISAM 的主键索引确实需要回表， 因为它的主键索引的叶子节点存放的是指针。但是如果 SQL 查的就是主键呢?**

```text
SELECT id FROM table WHERE id=1;
```

**主键索引本身的 key 就是主键，查到返回就行了。**

**这种情况就称之为覆盖索引了。**

## 覆盖索引



如果一个索引包含（覆盖）所有需要查询的字段的值，我们就称之为 “覆盖索引”。

在 InnoDB 存储引擎中，如果不是主键索引，**叶子节点存储的是主键 + 列值**，最终还是需要“回表查询”，就是还需要通过主键再查找一次。

这样就会比较，如果要查询出的列和索引是对应的，不做回表操作！



**覆盖索引即需要查询的字段正好是索引的字段，那么直接根据该索引，就可以查到数据了， 而无需回表查询。**

> 如主键索引，如果一条 SQL 需要查询主键，那么正好根据主键索引就可以查到主键。
>
> 再如普通索引，如果***一条 SQL 需要查询 name，name 字段正好有索引， 那么直接根据这个索引就可以查到数据，也无需回表***。

覆盖索引: 

![img](../picture/MySQL/20210420165341868.png)

















## 最左前缀原则 / 联合索引



MySQL中的索引可以以 **一定顺序引用多列**，称为联合索引。如 User 表的 name 和 city 加联合索引就是 (name, city)

而最左前缀原则指的是：**如果查询的时候查询条件<精确匹配索引的==左边==>连续一列或几列，则此列就可以被用到**

如：

```mysql
select * from user where name=xx and city=xx ; ／／可以命中索引
select * from user where name=xx ; // 可以命中索引
select * from user where city=xx ; // 无法命中索引            
```

> 这里需要注意的是，查询的时候如果两个条件都用上了，但是顺序不同，如 `city= xx and name ＝xx`，那么现在的查询引擎会自动优化为匹配联合索引的顺序，这样是能够命中索引的。



由于最左前缀原则，在创建联合索引时，索引字段的顺序需要考虑**字段值去重之后的个数，较多的放前面(才能使得索引 尽可能多的匹配到查询语句)**。

ORDER BY子句也遵循此规则。





## 注意避免重复 / 冗余索引





mysql允许在**相同列上创建多个索引**，无论是有意还是无意，mysql需要**<u>单独维护重复的索引</u>**，并且优化器在优化查询的时候也需要逐个地进行考虑，这会影响性能。

　　重复索引是指的在**相同的列上按照相同的顺序创建的相同类型的索引**，应该避免这样创建重复索引，发现以后也应该立即删除。但，在相同的列上创建**不同类型的索引**来满足不同的查询需求是可以的。

```mysql
CREATE TABLE test(
  ID INT NOT NULL PRIMARY KEY,
  A INT NOT NULL,
  B INT NOT NULL,
  UNIQUE(ID),
  INDEX(ID),
) ENGINE=InnoDB;
```

这段SQL创建了3个重复索引。通常并没有理由这么做。

---

冗余索引和重复索引有一些不同，如果创建了索引（a,b），再创建索引（a）就是冗余索引，因为这只是前面一个索引的  **<u>前缀索引</u>**，因此（a,b）也可以当作(a)来使用，但是**（b,a）就不是冗余索引，索引(b)也不是**，因为b不是索引（a,b）的最左前缀列。

另外，其他不同类型的索引在相同列上创建（如哈希索引和全文索引）不会是B-Tree索引的冗余索引，而无论覆盖的索引列是什么。



例如，有人可能会增加一个新的索引(A,B)而不是索引(A)。还有一种情况是**将一个索引扩展为(A,ID)**  ,其中***ID是主键***，对于InnoDB来说**<u>*主键已经包含在二级索引中了，所以这也是冗余的  ！*</u>**



大多数情况下都不需要冗余索引，应该尽量扩展已有的索引而不是创建新索引，但有时候处于性能方面的考虑需要冗余索引，因为**扩展已有的索引**会导致其变得太大

![image-20210612200957950](../picture/MySQL/image-20210612200957950.png)



MySQLS.7 版本后，可以通过查询 sys 库的 `schema_redundant_indexes` 表来查看冗余索引





## MySQL 为表字段添加索引







1.添加PRIMARY KEY（主键索引）

```sql
ALTER TABLE `table_name` ADD PRIMARY KEY ( `column` ) 
```

2.添加UNIQUE(唯一索引)

```sql
ALTER TABLE `table_name` ADD UNIQUE ( `column` ) 
```

3.添加INDEX(普通索引)

```sql
ALTER TABLE `table_name` ADD INDEX index_name ( `column` )
```

4.添加FULLTEXT(全文索引)

```sql
ALTER TABLE `table_name` ADD FULLTEXT ( `column`) 
```

5.添加多列索引

```sql
ALTER TABLE `table_name` ADD INDEX index_name ( `column1`, `column2`, `column3` )
```







# MyIslam 与 InnoDB 的区别



**MyISAM是MySQL的默认数据库引擎（5.5版之前）**，由早期的 **ISAM** （Indexed Sequential Access Method：有索引的顺序访问方法）所改良。虽然性能极佳，而且提供了大量的特性，包括**全文索引、压缩、空间函数**等，

但**<u>MyISAM不支持事务和行级锁</u>**，而且最大的缺陷就是**崩溃后无法安全恢复**。不过，5.5版本之后，**MySQL引入了InnoDB**（另一种数据库引擎）。

大多数时候我们使用的都是InnoDB存储引擎，但是在某些情况下使用 MyISAM 也是合适的比如**<u>读密集</u>**的情况下。（如果你不介意 MyISAM 崩溃回复问题的话）。



**两者的对比：**

1. **是否支持行级锁** : MyISAM 只有表级锁(table-level locking)，而InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。

2. **是否支持事务和崩溃后的安全恢复： MyISAM** 强调的是性能，每次查询具有原子性,其执行数度比InnoDB类型更快，但是不提供事务支持。但是**InnoDB** 提供事务支持事务，外部键等高级数据库功能。 具有事务(commit)、回滚(rollback)和崩溃修复能力(crash recovery capabilities)的事务安全(transaction-safe (ACID compliant))型表。

3. **是否支持外键：** MyISAM不支持，而InnoDB支持。

4. **是否支持MVCC** ：**仅 InnoDB 支持**。

   应对高并发事务, **MVCC比单纯的加锁更高效**;  

   MVCC只在 `读已提交READ COMMITTED` 和 `可重复读REPEATABLE READ` **两个隔离级别下工作**;   

   MVCC可以使用 **乐观(optimistic)锁 和 悲观(pessimistic)锁来实现**;

   各数据库中MVCC实现并不统一。

   推荐阅读：[MySQL-InnoDB-MVCC多版本并发控制](https://segmentfault.com/a/1190000012650596)

5. ......



> **不要轻易相信“MyISAM比InnoDB快”之类的经验之谈**，这个结论往往不是绝对的。在很多我们已知场景中，InnoDB的速度都可以让MyISAM望尘莫及，尤其是用到了**聚簇索引**，或者需要访问的数据都可以放入内存的应用。
>
> ————《高性能MySQL》





# 乐观锁和悲观锁



---

### 悲观锁

总是假设最坏的情况，每次去拿数据的时候**都认为别人会修改**，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会**阻塞直到它拿到锁**（**共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程**）。

**传统的关系型数据库**里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在**做操作之前先上锁**。Java中`synchronized`和`ReentrantLock`等**独占锁**就是悲观锁思想的实现。



----

### 乐观锁

总是假设最好的情况，每次去拿数据的时候**<u>都认为别人不会修改</u>**，所以不会上锁，但是在更新的时候会**<u>判断一下在此期间别人有没有去更新这个数据</u>**，可以使用**<u>版本号机制</u>**和**<u>CAS算法</u>**实现。

**乐观锁适用于<多读>的应用类型，这样可以提高吞吐量**，像数据库提供的类似于**write_condition机制**，其实都是提供的乐观锁。在Java中`java.util.concurrent.atomic`包下面的原子变量类就是使用了乐观锁的一种实现方式**CAS**实现的。



---

### 两种锁的使用场景



**乐观锁一般会使用 版本号机制 或 CAS算法实现**



---

1. 版本号机制

一般是在数据表中加上一个**数据版本号version字段**，表示数据被修改的次数，当数据被修改时，**version值会加一**。当线程A要更新数据值时，在**读取数据的同时也会读取version值**，在提交更新时，若**刚才读取到的version值和   当前数据库中的version值相等时**才更新，否则**重试**更新操作，直到更新成功。



> **举一个简单的例子：** 假设数据库中帐户信息表中有一个 version 字段，当前值为 1 ；而当前帐户余额字段（ balance ）为 $100 。
>
> 1. 操作员 A 此时将其读出（ version=1 ），并从其帐户余额中扣除 50（100-$50 ）。
> 2. 在操作员 A 操作的过程中，操作员B 也读入此用户信息（ version=1 ），并从其帐户余额中扣除 20（100-$20 ）。
> 3. 操作员 A 完成了修改工作，将数据版本号加一（ version=2 ），连同帐户扣除后余额（ balance=$50 ），提交至数据库更新，此时由于提交数据版本大于数据库记录当前版本，数据被更新，数据库记录 version 更新为 2 。
> 4. 操作员 B 完成了操作，也将版本号加一（ version=2 ）试图向数据库提交数据（ balance=$80 ），但此时比对数据库记录版本时发现，操作员 B 提交的数据版本号为 2 ，数据库记录当前版本也为 2 ，不满足 “ 提交版本必须大于记录当前版本才能执行更新 “ 的乐观锁策略，因此，**<u>操作员 B 的提交被驳回</u>**。
>
> 这样，就**避免了操作员 B 用基于 version=1 的旧数据修改的结果覆盖操作员A 的操作结果的可能。**





---

2. CAS算法

即**compare and swap（比较与交换）**，是一种有名的**无锁算法**。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。**CAS算法**涉及到三个操作数

- 需要读写的内存值 V
- 进行比较的值 A
- 拟写入的新值 B

当且仅当 V 的值等于 A时，CAS通过原子方式用新值B来更新V的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个**自旋操作**，即**不断的重试**。

```java
public final int getAndAddInt(Object var1, long var2, int var4) {
    int var5;
    do {
        //获取最新值 var5
        var5 = this.getIntVolatile(var1, var2);
    } while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4));//如果当前值不等于上次获得的值 var5，那么继续自旋，说明有人修改了这个值
	
    //最后返回修改前的旧值
    return var5;
}
```

https://blog.csdn.net/qq_34337272/article/details/81252853





### 乐观锁的缺点





> **ABA问题是 乐观锁一个常见的问题**



---

1. ABA问题

如果一个变量V初次读取的时候是A值，并且在准备赋值的时候检查到它仍然是A值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回A，那CAS操作就会误认为它从来没有被修改过。这个问题被称为CAS操作的 **"ABA"问题。**

JDK 1.5 以后的 `AtomicStampedReference 类`就提供了此种能力，其中的 `compareAndSet 方法`就是首先**<u>检查当前引用是否等于预期引用，并且当前标志是否等于预期标志</u>**，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。



---

2. 循环时间长、开销大

**自旋 CAS（不成功就一直循环执行直到成功），如果长时间不成功，会给 CPU 带来非常大的执行开销**

如果JVM能支持**处理器提供的pause指令**那么效率会有一定的提升，pause指令有两个作用：

- 第一它可以**延迟流水线执行指令**（de-pipeline）,**使 CPU 不会消耗过多的执行资源**，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。

- 第二它可以避免在退出循环的时候因**内存顺序冲突**（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。

---

3. 只能保证一个共享变量的原子操作

CAS 只对**单个共享变量**有效，当操作涉及**跨多个共享变量**时 CAS 无效。

但是从 JDK 1.5开始，提供了`AtomicReference类`来保证**引用对象之间的原子性**，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用`AtomicReference类`**把多个共享变量合并成一个共享变量来操作。**





# 锁机制与 InnoDB 锁算法

---

**MyISAM 和 InnoDB 存储引擎使用的锁：**

- MyISAM 采用表级锁（table-level locking）
- InnoDB 支持 **行级锁**（row-level locking） 和表级锁，默认为 **行级锁**



---

**表级锁和行级锁对比：**

- **表级锁：**MySQL中锁定 **力度最大**  的一种锁，对当前操作的**整张表加锁**，实现简单，资源消耗也比较少，加锁快，**<u>不会出现死锁</u>**。其锁定粒度最大，**触发锁冲突的概率最高，并发度最低**，MyISAM和 InnoDB引擎都支持表级锁。

- **行级锁：** Mysql中锁定 **粒度最小** 的一种锁，只针对当前操作的行进行加锁。 **行级锁能大大减少数据库操作的冲突**。其加锁粒度最小，并发度高，但加锁的开销也最大，加锁慢，**<u>会出现死锁</u>**。



https://blog.csdn.net/qq_34337272/article/details/80611486



---

**InnoDB存储引擎的锁的算法有三种：**

- Record lock：单个行记录上的锁
- Gap lock：间隙锁，**锁定一个范围**，**<u>不包括记录本身</u>**。锁加在不存在的空闲空间，可以是两个索引记录之间，也可能是第一个索引记录之前或最后一个索引之后的空间。
- Next-key lock：**record + gap** 锁定一个范围，**<u>包括记录本身</u>**



> 当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，
> 叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁。
>
>
> 间隙锁在InnoDB的唯一作用就是防止其它事务的插入操作，以此来达到防止幻读的发生，所以间隙锁不分什么共享锁与排它锁。
>
> 要禁止间隙锁的话，可以把隔离级别降为读已提交，或者开启参数innodb_locks_unsafe_for_binlog。



---

**注意：**

1. InnoDB 对于**行的查询**使用 next-key lock
2. Next-key lock 为了**解决 Phantom Problem 幻读问题**
3. 当查询的索引含有唯一属性时，将 next-key lock 降级为 record key
4. Gap锁设计的目的是为了阻止多个事务将**记录插入到同一范围内**，而这会导致**幻读问题**的产生
5. 有两种方式显式**关闭gap锁**：（除了外键约束和唯一性检查外，其余情况仅使用record lock） A. 将事务隔离级别设置为RC(读已提交) B. 将参数innodb_locks_unsafe_for_binlog设置为1





# 大表优化



MySQL单表记录数过大时，数据库的CRUD性能会明显下降，一些常见的优化措施如下：



1. **限定数据的范围**

务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内；



2. **读写分离**

经典的数据库拆分方案，主库负责写，从库负责读；



3. **垂直分区**

**根据数据库里面数据表的相关性进行拆分。** 例如，用户表中既有用户的登录信息又有用户的基本信息，可以**将用户表拆分成两个单独的表**，甚至放到单独的库做分库。

**简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表。** 如下图所示，这样来说大家应该就更容易理解了。

![数据库垂直分区](../picture/MySQL/aa62487e11b370755df5e16bcc7330b8.png)



- **垂直拆分的优点：** 可以使得**列数据变小**，在**查询时减少读取的Block数，减少I/O次数**。此外，垂直分区可以简化表的结构，易于维护。
- **垂直拆分的缺点：** **主键会出现冗余**，需要管理冗余列，并会**引起Join操作**，可以通过在应用层进行Join来解决。此外，垂直分区会**让事务变得更加复杂；**



4. **水平分区**

**保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。 水平拆分可以支撑非常大的数据量。**

水平拆分是指数据表行的拆分，表的行数超过200万行时，就会变慢，这时可以**把一张的表的数据拆成多张表来存放**。

举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以**避免单一表数据量过大对性能造成影响。**

![数据库水平拆分](../picture/MySQL/8d5aff7c0cf502863faf1cd4c1dbc73d.png)





**水平拆分可以支持非常大的数据量**

分表仅仅解决了单一表数据过大的问题，但由于**表的数据还是在同一台机器**，对于提升**MySQL并发能力**并没有什么意义，**水平拆分最好分库**



水平拆分能够 **支持非常大的数据量存储，应用端改造也少**，但 **分片事务难以解决** ，跨节点Join性能较差，逻辑复杂。《Java工程师修炼之道》的作者推荐 **尽量不要对数据进行分片，因为拆分会带来逻辑、部署、运维的各种复杂度** ，一般的数据表在优化得当的情况下支撑千万以下的数据量是没有太大问题的。如果实在要分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络I/O。



**数据库分片的两种常见方案：**

- **客户端代理**：**分片逻辑在应用端，封装在jar包中，通过修改或者封装JDBC层来实现。** 当当网的 **Sharding-JDBC** 、阿里的TDDL是两种比较常用的实现。
- **中间件代理**： **在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。** 我们现在谈的 **Mycat** 、360的Atlas、网易的DDB等等都是这种架构的实现。





# **读写分离**







![读写分离](../picture/MySQL/9c624bc130d053860a5089cb9a53310a.png)



一般情况下，选择 **一主多从**，也就是**一台主数据库负责写，其他的从数据库负责读。**

主库和从库之间会**进行数据同步**，以**保证从库中数据的准确性**。





----

## 读写分离会带来什么问题？如何解决？





对于提升数据库的并发非常有效，但是会引来一个问题：**主库和从库的数据存在延迟**。比如你写完主库之后，**主库的数据同步到从库需要时间的，这个时间差就导致了 主库和从库的数据不一致性问题**。

即：**主从同步延迟** 



----

主从同步延迟问题的解决，没有特别好的一种方案，只能根据自己的业务场景来考虑。

以下有几种解决方法：

1. **强制将读请求路由到主库处理**

既然从库的数据过期了，那我直接从主库读取？？会增加主库的压力！不过实现起来比较简单，使用的最多

比如 `Sharding-JDBC` 就是采用的这种方案。**通过使用 Sharding-JDBC 的 `HintManager` 分片键值管理器，我们可以强制使用主库。**

```java
HintManager hintManager = HintManager.getInstance();
hintManager.setMasterRouteOnly();
// 继续JDBC操作
```

对于这种方案，你可以将那些**<u>必须获取最新数据的读请求</u>**都交给主库处理。

如果对时效性要求不那么高，就去从库中读取



2. **延迟读取**

既然主从同步存在延迟，那我就在**延迟之后读取**啊，比如主从同步延迟 0.5s,那我就 1s 之后再读取数据。这样多方便啊！方便是方便，但是也很扯淡。

不过，如果你是这样**设计业务流程**就会好很多：对于一些**对数据比较敏感**的场景，你可以在**完成写请求之后，避免立即进行请求操作**。比如你支付成功之后，跳转到一个支付成功的页面，当你点击返回之后才返回自己的账户（进行一些跳转，作为同步的延迟）。



> **更多方法，见 MySQL 实战 45 讲《读写分离有哪些坑》**







## 如何实现读写分离



实现读写分离一般包括以下几步：

1. **部署多台数据库，选择其中的一台作为主数据库**，其他的一台或者多台作为从数据库
2. 保证主数据库和从数据库之间的数据是实时同步的，这个过程就是我们常说的 **主从复制**
3. 系统将写请求交给主数据库处理，读请求交给从数据库处理



----

项目中常用的方式有两种：

1. **代理方式**

![读写分离-代理层](../picture/MySQL/461112716e30db118f4c784adc6e2ff7.png)

在应用和数据库中间加一个代理层。应用程序所有的数据请求都交给代理层处理，代理层负责分离读写请求，将它们路由到对应的数据库中



提供类似功能的中间件有 **MySQL Router**（官方）、**Atlas**（基于 MySQL Proxy）、**Maxscale**、**MyCat**。



2. **组件方式**

引入第三方组件来帮助我们读写请求

这种方式目前在各种互联网公司中用的最多的，相关的实际的案例也非常多。如果你要采用这种方式的话，推荐使用 `sharding-jdbc` ，**直接引入 jar 包即可使用，非常方便。同时，也节省了很多运维的成本**



> 可以在 shardingsphere 官方找到[sharding-jdbc 关于读写分离的操作](https://shardingsphere.apache.org/document/legacy/3.x/document/cn/manual/sharding-jdbc/usage/read-write-splitting/)。







## 主从复制原理



MySQL binlog(binary log 即**二进制日志文件**) 主要记录了 MySQL 数据库中数据的所有变化(**<u>数据库执行的所有 DDL(数据定义语言)  和 DML(数据库操作语言) 语句</u>**)。

因此，我们根据主库的 **MySQL binlog 日志就能够将主库的数据同步到从库中**。

更具体和详细的过程是这个样子的（图片来自于：[《MySQL Master-Slave Replication on the Same Machine》](https://www.toptal.com/mysql/mysql-master-slave-replication-tutorial)）：



![MySQL主从复制](../picture/MySQL/78816271d3ab52424bfd5ad3086c1a0f.png)

1. **<u>主库</u>**将数据库中**数据的变化写入到 binlog**
2. 从库连接主库
3. 从库会创建一个 I/O 线程**<u>向主库请求更新的 binlog</u>**
4. 主库会创建一个 **<u>binlog dump 线程来发送 binlog</u>**，从库中的 I/O 线程负责**接收**
5. 从库的 I/O 线程**将接收的 binlog 写入到 relay log 中**
6. 从库的 SQL 线程**读取 relay log 同步数据本地**（再执行一遍 SQL）



看到binlog就要想到**主从复制**。除了主从复制之外，binlog还能帮助我们实现**数据恢复**



阿里开源的 canal 工具。

这个工具**可以帮助我们实现 MySQL 和其他数据源比如 Elasticsearch 或者另外一台 MySQL 数据库之间的数据同步**。很显然，这个工具的底层原理肯定也是**<u>依赖 binlog</u>**。canal 的原理就是**模拟 MySQL 主从复制的过程**，**解析 binlog 将数据同步到其他的数据源。**

常用的**分布式缓存组件 Redis 也是通过主从复制**实现的读写分离。



---

简单总结一下：**MySQL 主从复制是依赖于 binlog 。另外，常见的一些同步 MySQL 数据到其他数据源的工具（比如 canal）的底层一般也是依赖 binlog 。**

































# 分库分表



读写分离是 **应对数据库读并发过高**，没有解决数据库存储问题。

**如果MySQL一张表的数据量过大怎么办？如何将解决 MySQL 的存储压力呢？**

**分库分表！**



## 什么是分库分表



**分库** 就是将数据库中的数据分散到不同的数据库上

- 将数据库中的**用户表和用户订单表**分别放在两个不同的数据库
- 由于用户表**数据量太大**，对用户表进行水平切分，将切分后的2张用户表**分别放在两个不同的数据库**





---

**分表** 就是对单表的数据进行切分，可以是垂直拆分，也可以是水平拆分

- **垂直拆分？**

  对数据表 **列** 的拆分，把一张列比较多的表拆分为多张表

  :chestnut: 将用户信息表中的**一些列单独抽出来**作为一个表。



- **水平拆分？**

  对数据表行的拆分，把一张行比较多的表拆分为多张表

  :chestnut: 我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。



![img](../picture/MySQL/662ea3bda90061d0b40177e3a46fefc3.jpg)







## 什么情况需要分库分表





遇到下面几种场景可以考虑分库分表：

- **单表**的数据达到千万级别以上，数据库**读写速度比较缓慢**（分表）。
- 数据库中的数据**占用的空间**越来越大，备份时间越来越长（分库）。
- 应用的**并发量太大**（**<u>分库</u>**）。





## 分库分表带来什么问题？



在公司做的任何技术决策，不光是要考虑这个技术能不能满足我们的要求，是否适合当前业务场景，还要重点考虑其带来的成本。

引入分库分表之后，会给系统带来什么挑战呢？

- **join 操作** ： 同一个数据库中的表**分布在了不同的数据库中**，导致**无法使用 join 操作**。这样就导致我们需要**手动进行数据的封装**，比如你在一个数据库中查询到一个数据之后，再根据这个数据去另外一个数据库中找对应的数据。
- **事务问题** ：同一个数据库中的表分布在了不同的数据库中，如果**单个操作涉及到多个数据库，那么数据库自带的事务就无法满足我们的要求了**。
- **分布式 id** ：分库之后， 数据遍布在不同服务器上的数据库，数据库的自增主键已经没办法满足**生成的主键唯一id**了。我们如何为不同的数据节点生成全局唯一主键呢？这个时候，我们就需要**为我们的系统引入<u>分布式 id</u> 了。**
- ......

另外，引入分库分表之后，一般需要 DBA 的参与，同时还**需要更多的数据库服务器**，这些都属于成本。





## 分库分表推荐方案



ShardingSphere 项目（包括 Sharding-JDBC、Sharding-Proxy 和 Sharding-Sidecar）是当当捐入 Apache 的，目前主要由京东数科的一些巨佬维护。



![img](../picture/MySQL/3f162082cc6d23c632e451190e79a469.image)



除了支持读写分离和分库分表，还提供分布式事务、数据库治理等功能

[芋道 Spring Boot 分库分表入门](https://mp.weixin.qq.com/s/A2MYOFT7SP-7kGOon8qJaw)





## 分库分表后，数据怎么迁移



如何将老库的数据迁移到新库？

- **停机迁移**，写个脚本将单表数据写到新库。
- **双写方案**，针对那些不能停机迁移的场景
  - 对于程序层面，**对老库的更新操作**，同时也要写入分库分表后的新数据库系统。这样就能**保证新库里的数据是最新的**
  - 写一个脚本将老的单机数据库的数据写入到分库分表后的数据库系统
  - 写一个脚本**<u>检查</u>**新库数据的准确性以及是否有遗漏的数据
  - 如果老库完全迁移到新库，将程序中数据库配置的属性改为新库就行~（ :chestnut: 分布式配置中心）





----

有没有一种不停机并且不用怎么改动项目代码的方法呢？？

我们可以利用**数据库同步工具 canal 来获取老库的 binglog 并解析**，我们根据解析的结果**将数据写入到新库中去**。





## 除了分库分表，还有其他方法吗

除了这分库分表种解决方案之外，目前还有很多公司使用了目前比较火的一个开源的分布式关系型数据库 **TiDB**。

对于，TiDB 来说根本不用担心数据库存储压力，可以为我们节省很多事情。

并且，TiDB 天然支持水平扩容或者缩容、金融级高可用，并且，兼容 MySQL 5.7 协议和 MySQL 生态。非常适合高可用、强一致要求较高、数据规模较大等各种应用场景。















# 实践





## 阿里巴巴Java开发手册数据库部分



1. **模糊查询**

对于模糊查询阿里巴巴开发手册这样说到：

> **<u>【强制】</u>**页面搜索**严禁左模糊或者全模糊**，如果需要请走**<u>搜索引擎</u>**来解决。
>
> 说明:索引文件具有 B-Tree 的**最左前缀匹配特性**，如果左边的值未确定，那么无法使用此索引。





---

2. 外键和级联

对于外键和级联，阿里巴巴开发手册这样说到：

> **<u>【强制】</u>**不得使用外键与级联，**一切外键概念必须在应用层解决**。
>
> 说明:以学生和成绩的关系为例，学生表中的 student_id 是主键，那么成绩表中的 student_id 则为外键。
>
> 如果**更新学生表中的 student_id，同时触发成绩表中的 student_id 更新，即为级联更新**。
>
> 外键与级联更新适用于**<u>单机低并发，不适合分布式、高并发集群</u>**;
>
> 级联更新是**强阻塞**，存在数据库更新风暴的风险;
>
> **外键影响数据库的插入速度**



---

**为什么不要用外键呢？**大部分人可能会这样回答：

> 1. **增加了复杂性：** 
>
>    a.每次做 DELETE 或者 UPDATE 都**必须考虑外键约束**，会导致开发的时候很痛苦,   测试数据极为不方便;
>
>    b.外键的**主从关系是定的**，假如哪天**需求有变化**，数据库中的这个字段根本不需要和其他表有关联的话就会增加很多麻烦。
>
> 2. 外键还会因为需要请求**对其他表内部加锁**而容易出现死锁情况；
>
> 3. **对分库分表不友好** ：因为**分库分表下外键是无法生效**的。
>
> 4. ......



外键也是有很多好处的，比如：

1. 保证了**数据库数据的一致性和完整性**；
2. **级联操作方便**，减轻了程序代码量；
3. ......









---

3. `@Transactional`事务注解



对于`@Transactional`事务注解，阿里巴巴开发手册这样说到：

> 【参考】@Transactional事务不要滥用。**事务会影响数据库的QPS**，另外使用事务的地方需要**考虑各方面的回滚方案**，包括缓存回滚、搜索引擎回滚、消息补偿、统计修正等。











## 创建索引的注意事项

1. **选择合适的字段创建索引**
   - **不为 NULL 的字段**：索引字段的数据应该尽量不为 NULL，因为对于数据为 NULL 的字段，数据库较难优化。如果字段频繁被查询，但又避免不了为 NULL，建议使用 0,1,true,false 这样语义较为清晰的短值或短字符作为替代
   - **被频繁查询的字段**：我们创建索引的字段应该是查询操作非常频繁的字段。
   - **被作为条件查询的字段**：被作为 WHERE 条件查询的字段，应该被考虑建立索引。
   - **频繁需要排序的字段**：索引已经排序，这样查询可以利用索引的排序，加快排序查询时间。
   - **被经常频繁用于<连接>的字段**：经常用于连接的字段可能是一些外键列，对于外键列并不一定要建立外键，只是说该列涉及到表与表的关系。对于频繁被连接查询的字段，可以考虑建立索引，提高多表连接查询的效率。



2. **被频繁更新的字段应该<慎重建立索引>**

虽然索引能带来查询上的效率，但是维护索引的成本也是不小的。 如果一个字段**不被经常查询，反而被经常修改**，那么就更不应该在这种字段上建立索引了。



3. **尽可能的考虑建立联合索引而不是单列索引**

因为索引是需要占用磁盘空间的，可以简单理解为**每个索引都对应着一颗 B+树**。如果一个表的字段过多，索引过多，那么当这个表的数据达到一个体量后，索引占用的空间也是很多的，且修改索引时，耗费的时间也是较多的。

如果是联合索引，**多个字段在一个索引上，那么将会节约很大磁盘空间，且修改数据的操作效率也会提升。**



4. **注意避免冗余索引**

冗余索引指的是索引的功能相同，**能够命中索引(a, b)就肯定能命中索引(a) ，那么索引(a)就是冗余索引。**

:chestnut: （name,city ）和（name ）这两个索引就是冗余索引，能够命中前者的查询肯定是能够命中后者的 在大多数情况下，都应该尽量扩展已有的索引而不是创建新索引。



5. **考虑在字符串类型的字段上使用前缀索引代替普通索引**

前缀索引仅限于字符串类型，**较普通索引会占用更小的空间**，所以可以考虑使用前缀索引带替普通索引。



## 一些建议



- 对于**中到大型表**索引都是非常有效的，但是特大型表的话维护开销会很大，不适合建索引
- 避免 **where 子句中对字段施加函数，这会造成无法命中索引。**
- 在使用 InnoDB 时使用**与业务无关的自增主键作为主键**，即使用逻辑主键，而不要使用业务主键。
- 删除长期未使用的索引，不用的索引的存在会造成不必要的性能损耗 MySQL 5.7 可以通过查询 sys 库的 schema_unused_indexes 视图来查询哪些索引从未被使用
- 在使用 limit offset（**分页查询，直接通过索引结构的 B+ 树**） 查询缓慢时，可以**借助索引来提高性能**





# 一条SQL查询语句是如何执行的？  





## MySQL 基础架构





![image-20210615095651309](../picture/MySQL/image-20210615095651309.png)

MySQL可以分为  **Server层**  和 **存储引擎** 两部分

- **Server层**：包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的 **内置函数(日期、时间、数学和加密函数等)**，所有 **跨存储引擎的功能** 都在这一层实现，比如存储过程、触发器、视图等

- **存储引擎**：**负责数据的存储和提取**。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory等多个存储引擎。InnoDB从 MySQL5.5.5版本后成为**默认存储引擎**

> 如果执行 `create table` 建表的时候不明确指定引擎类型，默认使用的就是 InnoDB。也可以指定存储引擎的类型：`engine=memory`。不同存储引擎的表数据存取方式不同，支持的功能也不同



不同的存储引擎共用一个 Server 层，即：从连接器到执行器的部分。



## 连接器



首先会连接到这个数据库上，**连接器负责跟客户端建立连接、获取权限、维持和管理连接。**

连接命令

```
mysql -h$ip -P$port -u$user -p
```

然后输入密码，即可完成连接。

连接命令中的 mysql 是 **客户端工具，用来跟服务器建立连接。**在完成经典的TCP握手之后，连接器就要开始认证身份，**到权限表中查出我拥有的权限，之后，这个连接里面的权限判断逻辑，都将依赖于此时独到的权限**

即：一个用户成功建立连接后，即使用管理员账号对这个用户的权限做了修改，也**不会影响已经存在连接的权限**。修改完成后，只有新建的连接才会使用新的权限设置

在show processlist命令中看到各个连接的状态

![image-20210615100917121](../picture/MySQL/image-20210615100917121.png)

默认 8小时 没动静，连接器会自动断开，参数 `wait_timeout`



---

尽量使用长连接，但可能 MySQL 的内存涨的很快，因为MySQL在执行过程中**<u>临时使用的内存</u>**是**<u>管理在连接对象里面</u>**的，长连接积累，内存占用太大，被OOM，即MySQL异常重启

解决：

1. 定期断开长连接，使用一段时间，或者执行了一个占用内存的大查询，断开连接，需要再重连
2. 如果你用的是MySQL 5.7或更新版本， 可以在每次执行一个比较大的操作后， 通过执行`mysql_reset_connection`来**重新初始化连接资源**。 这个过程**不需要重连和重新做权限验证**，但是会将连接恢复到刚刚创建完时的状态。  



## 查询缓存(mysql8.0删除该功能)



连接建立完成后，就可以执行 select 语句了。

MySQL 拿到一个查询请求后，先到查询缓存看看，**是否之前执行过这条语句**。之前执行过的语句及其结果会以 k-v对 的形式，倍之间缓存在内存中。k：查询的语句，v：查询的结果。

如果语句不在查询缓存中，继续后面的执行阶段。**执行完成后，执行结果会被缓存到查询缓存中**。如果查询 **命中缓存**，MySQL不需要执行后面的复杂操作，直接返回结果，效率看似很高！



> **但是建议不要使用查询缓存，因为查询缓存往往弊大于利**

查询缓存的 **失效** 非常频繁，只要有一个对 **表的更新**，这个表上所有的查询缓存都会被清空。

很可能你费劲地把结果存起来， 还没使用呢， 就被一个更新全清空了。 **对于更新压力大的数据库来说， 查询缓存的命中率会非常低**。 除非你的业务就是有一张**静态表**， 很长时间才会更新一次。比如， **一个系统配置表， 那这张表上的查询才适合使用查询缓存**  



好在 MySQL 提供了关闭 / 开启 查询缓存的参数，将my.cnf中的参数query_cache_type设置成DEMAND， 这样**对于默认的SQL语句都不使用查询缓存**。 而对于你确定要使用查询缓存的语句， 可以用SQL_CACHE显式指定， 像下面这个语句一样：  

```sql
mysql> select SQL_CACHE * from T where ID=10；
```



**需要注意的是， MySQL 8.0版本直接将查询缓存的整块功能删掉了， 也就是说8.0开始彻底没有这个功能了。  **





## 分析器



如果没命中查询缓存，就要开始执行语句了！对SQL语句做解析

分析器先做 **词法分析**。输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么？代表什么？

MySQL从你输入的"select"这个关键字识别出来， 这是一个查询语句。 它也要把字符串“T”识别成“表名T”， 把字符串“ID”识别成“列ID”。
做完了这些识别以后， 就要做“语法分析”。 根据词法分析的结果， 语法分析器会根据语法规则，**判断你输入的这个SQL语句是否满足MySQL语法**。

如果你的语句不对， 就会收到“You have an error in your SQL syntax”的错误提醒。

> 一般语法错误会提示**第一个出现错误的位置**， 所以你要关注的是紧接“use near”的内容 





## 优化器



经过分析器，MySQL知道你要做什么了。

优化器是在表里面有多个索引的时候，**<u>决定使用哪个索引</u>**，

或者在一个语句有多表关联（join）的时候，**<u>决定各个表的连接顺序</u>**。比如执行下面语句进行两个表的join：

```mysql
select * from t1 join t2 where t1.c=10 and t2.d=20
```

- 既可以先从表t1里面取出c=10的记录的ID值， 再根据ID值关联到表t2， 再判断t2里面d的值是否等于20。
- 也可以先从表t2里面取出d=20的记录的ID值， 再根据ID值关联到t1， 再判断t1里面c的值是否等于10。  

**两种方法的逻辑结果一样，但效率会不同！这就是优化器做的事情~**

优化器阶段完成后，语句的执行方案就确定了，进行执行器阶段。



## 执行器



MySQL通过分析器知道你要做什么，通过优化器知道了该怎么做，就进入了执行器阶段，开始执行语句。



当前是进行的查询操作，**那么就要応判断一下你对这个表 T 是否有执行查询的权限，如果没有，就会返回没有权限的错误：**

```mysql
mysql> select * from T where ID=10;

ERROR 1142 (42000): SELECT command denied to user 'b'@'localhost' for table 'T'
```

如果有权限， 就**打开表继续执行**。 打开表的时候， 执行器就会根据表的引擎定义， 去**使用这个引擎提供的接口**。  



比如我们这个例子中的表T中， ID字段没有索引， 那么执行器的执行流程是这样的：

1. 调用**InnoDB引擎接口取这个表的第一行**， 判断ID值是不是10， 如果不是则跳过， 如果是则将这行存在结果集中(这里并不会直接返回，因为不知道ID这个属性是不是唯一的)；
2. 调用引擎接口**<u>取“下一行”</u>**， 重复相同的判断逻辑， **直到取到这个表的最后一行**。
3. 执行器将上述遍历过程中**所有满足条件的行**组成的记录集作为结果集返回给客户端。

至此， 这个语句就执行完成了

:warning:

对于有索引的表，执行的逻辑差不多： 第一次调用的是“**取满足条件的第一行**”这个接口，之后循环取 “**满足条件的下一行**”这个接口，**这些接口都时在存储引擎中已经定义好的**

会在数据库慢查询日志中看到一个 rows_examined 的字段，表示这个语句**执行过程中扫描了多少行**。这个值就是在执行器每次调用引擎获取数据行的时候累加的。  

> 在有些场景下， 执行器调用一次， 在**引擎内部则扫描了多行**， 因此引擎扫描行数跟rows_examined并不是完全相同的。   





----

![image-20210615154931507](../picture/MySQL/image-20210615154931507.png)

分析会分析关键词和语法







# 日志系统：SQL更新语句如何完成





建表：一个主键ID和一个整型字段c：

```mysql
create table T(
	ID int primary key,
	c int
);
```

如果要将 ID = 2 这一行的值加1，SQL语句：

```mysql
update T set c=c+1 where ID=2;
```



重温一下 SQL 语句的基本执行链路：

![MySQL的逻辑架构图](../picture/MySQL/image-20210615154656237.png)







- 执行语句前要先连接数据库，这是连接器干的事情
- 表上有更新的时候，和这个表有关的查询缓存就会失效，**这条语句会把表 T 上所有的缓存结果清空**
- 分析器通过词法和语法解析知道这是一条更新语句，优化器决定要使用 ID 这个索引，然后执行器负责具体执行，找到这一行，然后更新



**和查询流程不一样的是，更新流程还设计两个重要的日志模块，redo log（重做日志） 和 binlog（归档日志）。**



## redo log







如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL的设计者就用了类似酒店掌柜粉板的思路来提升更新效率。  

粉板和账本配合的整个过程，就是 MySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead-Logging，关键点就是 **先写日志，再写磁盘**

当有一条记录需要更新的时候，InnoDB引擎 就会先把记录写到 redo log里面，并更新内存。**这时候更新就算完成了**。同时，InnoDB引擎会在适当的时候，**将这个操作记录更新到磁盘里面**，而这个更新往往实在系统比较空闲的时候做。

注意：InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么这块“粉板”总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写，

如下图：

![image-20210615160508121](../picture/MySQL/image-20210615160508121.png)

write_pos 是**当前记录的位置**，一边往redo log中写，这个指针一边后移，写到第三号文件末尾后就回到第-号文件开头。

checkpoint 是当前要 **擦除**的位置，也是往后推移并且循环的，**擦除记录前要把记录更新到磁盘上的数据文件中**

write_pos 到 checkpoint 之间的是 **空着的部分**，可以用来记录新的操作。如果 write_pos 追上 checkpoint，表示 **redo log日志文件记满了！这时候不能再执行新的更新，得停下来擦除一些记录，即：把 checkpoint 推进一下**

:star::star::star::star::star:

有了 redo log，InnoDB可以保证即使数据库发生**异常重启**，**之前提交的记录都不会消失**，这个能力称为：**crash-safe**，（故障恢复的能力）





## binlog





MySQL整体来看，一共就两块：Server层，主要做的是 **MySQL 功能**层面的事情，还有一块是存储引擎层，负责**存储相关**的具体事宜。

**redo log 是 InnoDB 引擎特有的日志，而 Server层也有自己的日志，称为 binlog（归档日志）**



> 为啥有两份日志？
>
> 因为最开始MySQL里并没有InnoDB引擎。 MySQL自带的引擎是MyISAM， 但是MyISAM没有 crash-safe 的能力， binlog 日志只能用于归档。 而InnoDB是另一个公司以插件形式引入MySQL的， 既然只依靠***binlog是没有crash-safe能力的***， 所以InnoDB使用另外一套日志系统— — 也就是  redo log来实现crash-safe能力  



他们的不同之处：

1. **redo log 是 InnoDB引擎特有的**；binlog 是 MySQL 的 Server层实现的，**所有引擎都可以使用**
2. redo log是 **物理日志**，记录的是"在某个数据页上做了什么修改"；binlog是 **逻辑日志**，记录的是 **这个语句的原始逻辑**，比如 "给ID=2这一行的c字段+1"
3. redo log是 **循环写的**，空间是固定的，会用完；binlog是 **可以追加写入的**。"**追加写**"是指 binlog 文件写到一定大小后会切换到下一个文件，并不会覆盖以前的日志



## InnoDB执行update语句流程



1. 执行器先找引擎 取ID=2 这一行。ID是主键，引擎直接用树搜索找到这一条记录。如果ID=2这一行所在的**数据页**本来就**在内存中（涉及到置换算法）**，就直接返回给执行器

2. 执行器拿到引擎给的行数据，把这个值加1，得到新的一行数据，再**调用引擎接口写入这行新的数据**

3. 引擎将这行新数据***更新到内存中***，同时将这个更新操作***记录到 redo log里面***，此时redo log 处于 **prepare状态**。然后告知执行器**执行完成了**，随时可以提交事务

4. 执行器生成这个操作的 binlog，并**把binlog写入磁盘**

5. 执行器调用引擎的提交事务接口，引擎**把刚刚写入的 redo log 改成提交状态**，更新完成。



浅色表示在 **InnoDB 内部** 执行的，深色表示在 **执行器** 中执行的

![image-20210615235448403](../picture/MySQL/image-20210615235448403.png)



> 将redo log的写入拆成了两个步骤：prepare 和 commit，“**两阶段提交**”





## 两阶段提交



为什么需要两阶段提交呢？

**为了让两份日志之间的逻辑一致**。

:chestnut: 怎样让数据库恢复到半个月前任意一秒的状态？



binlog 会记录所有的逻辑操作，并且采用“追加写”的形式。如果备份系统中保存了最近半个月的所有binlog，那么就可以恢复！同时系统会定期做**整库备份**（一天 / 一周）

当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据：

- 首先，**找到最近的一次全量备份**，从这个备份恢复到**临时库**
- 然后，从备份的时间点开始，将**备份的 binlog** 依次取出来，**重放**到中午误删表之前的那个时刻

这样临时库就更误删之前的线上库一样了，然后将表数据恢复到线上库中



-----

所以为什么需要两阶段提交？

由于 redo log 和 binlog 是两个独立的逻辑，如果不用两阶段提交，要么就是先写完 redo log 再写 binlog，或者反过来，这样会有什么问题？

仍然用前面的update语句来做例子。 假设当前ID=2的行， 字段c的值是0， 再假设执行update语句过程中在写完第一个日志后， **第二个日志还没有写完期间发生了crash**， 会出现什么情况呢？  

1. **先写 redo log 后写 binlog**

   假设redo log写完，binlog还没写完的时候，MySQL进程异常重启。不过 redo log 写完后，系统即使崩溃，仍然能够恢复数据，所以恢复后c为1

   但是由于 binlog 没写完就 crash 了，这时候binlog没有记录这个语句。因此之后备份日志的时候，保存的 binlog 日志就没有这条语句。

   需要用 binlog 来恢复临时库的时候，由于**这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的c为0，与原库的值不同，导致不一致**



2. **先写 binlog 后写 redo log**

   在binlog 写完之后 crash，由于 redo log还没写，崩溃恢复以后这个事务是无效的，所以c的值还是0.但是 binlog 里面记录了："把c从0改成1" 这个日志，在之后用binlog来恢复的时候就多了一个事务出来，恢复出来的这一行的c的值就是1，又与原库不同了

如果不使用两阶段提交，那么数据库的状态就有可能和用它的日志恢复出来的库状态不一致。

:warning::warning::warning:

不只是误操作后需要用这个过程来恢复数据。 当你**需要扩容**的时候， 也就是需要再**多搭建一些备库来增加系统的读能力**的时候， 现在常见的做法也是用**全量备份加上应用binlog来实现的**， 这个“不一致”就会导致你的线上出现主从数据库不一致的情况。

简单说， redo log和binlog都可以用于表示事务的提交状态， 而两阶段提交就是**让这两个状态保持逻辑上的一致**  







`innodb_flush_log_at_trx_commit`  这个参数设置成1的时候，表示每次事务的redo log都直接持久化到磁盘。 这个参数建议设置成1， 这样可以保证MySQL异常重启之后数据不丢失。

`sync_binlog`  这个参数设置成1的时候， 表示每次事务的binlog都持久化到磁盘。 这个参数也建议设置成1， 这样可以保证MySQL异常重启之后binlog不丢失。  



----

定期全量备份的周期“**取决于系统重要性**， 有的是一天一备， 有的是一周一备”。 那么在什么场景下， **一天一备会比一周一备更有优势呢**？ 或者说， 它影响了这个**数据库系统的哪个指标**？  

好处是：**"最长恢复时间 RTO"**  更短。

在一天一备的模式里， 最坏情况下需要应用**一天的 binlog**。 比如， 你每天0点做一次全量备份，而要恢复出一个到昨天晚上23点的备份。

一周一备最坏情况就要应用**一周的 binlog **了  

当然这个是有成本的， 因为更频繁全量备份需要消耗更多存储空间， 所以这个RTO是成本换来的， 就需要你根据业务重要性来评估了。  

























































































































































































































































































































































































































































































































































































































































































































































































































































